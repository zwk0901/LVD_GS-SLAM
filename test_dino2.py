# enhanced_grounding_dino_sam_detection.py
import torch
import cv2
import numpy as np
from groundingdino.util.inference import load_model, load_image, predict
from groundingdino.util import box_ops
from PIL import Image
import torchvision
import time
import os
import colorsys
import glob
from pathlib import Path
import json
from datetime import datetime

# SAM imports
try:
    from segment_anything import SamPredictor, sam_model_registry

    SAM_AVAILABLE = True
    print("âœ… SAM is available")
except ImportError:
    SAM_AVAILABLE = False
    print("âŒ SAM not available. Install with: pip install segment-anything")


class EnhancedDynamicStaticDetector:
    """å¢å¼ºçš„åŠ¨æ€å’Œé™æ€ç‰©ä½“åˆ†ç±»æ£€æµ‹å™¨ + SAMç²¾ç¡®åˆ†å‰² + æ‰¹é‡å¤„ç†"""

    def __init__(self, grounding_dino_config, grounding_dino_checkpoint,
                 sam_checkpoint=None, device="cuda"):
        self.device = device
        self.grounding_dino_model = None
        self.sam_predictor = None

        # åŠ è½½Grounding DINO
        self.load_grounding_dino(grounding_dino_config, grounding_dino_checkpoint)

        # åŠ è½½SAM
        if sam_checkpoint and SAM_AVAILABLE:
            self.load_sam(sam_checkpoint)
        else:
            print("âš ï¸  SAMæœªå¯ç”¨ï¼Œå°†ä»…ä½¿ç”¨è¾¹ç•Œæ¡†")

        # å®šä¹‰åŠ¨æ€å’Œé™æ€ç‰©ä½“ç±»åˆ«
        self.dynamic_objects = {
            "primary": ["car", "truck", "bus", "motorcycle", "bicycle", "person", "pedestrian"],
            "secondary": ["vehicle", "automobile", "people", "bike", "motorbike", "van", "suv"],
            "specific": ["walking person", "moving car", "driving vehicle", "riding bicycle"]
        }

        self.static_objects = {
            "primary": ["building", "tree", "road", "sidewalk", "wall", "fence", "pole"],
            "secondary": ["house", "street", "pavement", "barrier", "traffic light", "street lamp"],
            "specific": ["traffic sign", "stop sign", "road sign", "fire hydrant", "mailbox", "bench"]
        }

        # å½©è‰²å¯è§†åŒ–é…ç½®
        self.setup_colors()

        # æ£€æµ‹å‚æ•°
        self.box_threshold = 0.15
        self.text_threshold = 0.15
        self.min_confidence = 0.15

    def load_grounding_dino(self, config_path, checkpoint_path):
        """åŠ è½½Grounding DINOæ¨¡å‹"""
        print("â³ åŠ è½½Grounding DINOæ¨¡å‹...")
        try:
            self.grounding_dino_model = load_model(config_path, checkpoint_path, device=self.device)
            print("âœ… Grounding DINOæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Grounding DINOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise e

    def load_sam(self, sam_checkpoint):
        """åŠ è½½SAMæ¨¡å‹"""
        print("â³ åŠ è½½SAMæ¨¡å‹...")
        try:
            if "vit_h" in sam_checkpoint:
                model_type = "vit_h"
            elif "vit_l" in sam_checkpoint:
                model_type = "vit_l"
            else:
                model_type = "vit_b"

            print(f"   ä½¿ç”¨SAMæ¨¡å‹ç±»å‹: {model_type}")
            sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
            sam.to(device=self.device)
            self.sam_predictor = SamPredictor(sam)
            print("âœ… SAMæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ SAMæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.sam_predictor = None

    def setup_colors(self):
        """è®¾ç½®å½©è‰²å¯è§†åŒ–é…ç½®"""
        # åŠ¨æ€å¯¹è±¡é¢œè‰²ï¼ˆæš–è‰²è°ƒï¼‰
        self.dynamic_colors = {
            'person': [0, 0, 255],  # çº¢è‰²
            'people': [0, 0, 255],
            'pedestrian': [0, 0, 255],

            'car': [0, 165, 255],  # æ©™è‰²
            'vehicle': [0, 165, 255],
            'automobile': [0, 165, 255],

            'truck': [0, 255, 255],  # é»„è‰²
            'bus': [255, 0, 255],  # å“çº¢è‰²
            'motorcycle': [255, 0, 128],  # ç²‰çº¢è‰²
            'bicycle': [128, 0, 255],  # ç´«è‰²
            'bike': [128, 0, 255],
        }

        # é™æ€å¯¹è±¡é¢œè‰²ï¼ˆå†·è‰²è°ƒï¼‰
        self.static_colors = {
            'building': [128, 128, 64],  # æ©„æ¦„è‰²
            'house': [128, 128, 64],
            'wall': [96, 96, 96],  # ç°è‰²
            'road': [64, 64, 64],  # æ·±ç°è‰²
            'street': [64, 64, 64],
            'sidewalk': [160, 160, 160],  # æµ…ç°è‰²
            'pavement': [128, 128, 128],

            'tree': [0, 100, 0],  # æ·±ç»¿è‰²
            'fence': [150, 150, 0],  # æ·±é»„è‰²
            'pole': [100, 50, 0],  # æ£•è‰²
            'traffic light': [0, 255, 0],  # ç»¿è‰²
            'street lamp': [100, 50, 0],
        }

        self.color_cache = {}
        self.class_count = 0

    def get_color_for_class(self, class_name, is_dynamic=True):
        """ä¸ºç±»åˆ«è·å–é¢œè‰²ï¼ˆBGRæ ¼å¼ï¼‰"""
        if class_name is None:
            class_name = f"{'dynamic' if is_dynamic else 'static'}_unknown_{self.class_count}"

        class_name = str(class_name).lower().strip()

        # é€‰æ‹©é¢„å®šä¹‰é¢œè‰²
        predefined_colors = self.dynamic_colors if is_dynamic else self.static_colors

        # ç²¾ç¡®åŒ¹é…
        if class_name in predefined_colors:
            return predefined_colors[class_name]

        # éƒ¨åˆ†åŒ¹é…
        for key, color in predefined_colors.items():
            if key in class_name or class_name in key:
                return color

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{class_name}_{is_dynamic}"
        if cache_key in self.color_cache:
            return self.color_cache[cache_key]

        # ç”Ÿæˆæ–°é¢œè‰²
        if is_dynamic:
            hue_base = 0  # çº¢è‰²åŸºç¡€
            hue_range = 60  # åˆ°é»„è‰²çš„èŒƒå›´
        else:
            hue_base = 180  # é’è‰²åŸºç¡€
            hue_range = 120  # åˆ°ç»¿è‰²çš„èŒƒå›´

        hue = (hue_base + (self.class_count * 137.5) % hue_range) % 360
        saturation = 0.6 + (self.class_count % 4) * 0.1
        value = 0.7 + (self.class_count % 3) * 0.15

        rgb = colorsys.hsv_to_rgb(hue / 360, saturation, value)
        bgr = [int(rgb[2] * 255), int(rgb[1] * 255), int(rgb[0] * 255)]

        self.color_cache[cache_key] = bgr
        self.class_count += 1
        return bgr

    # ================================
    # ğŸš€ æ‰¹é‡å¤„ç†åŠŸèƒ½
    # ================================

    def detect_folder_images(self, input_folder, output_base_dir="./batch_detection_results"):
        """
        æ‰¹é‡æ£€æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡ï¼Œä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºç‹¬ç«‹çš„ç»“æœæ–‡ä»¶å¤¹

        Args:
            input_folder: è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
            output_base_dir: è¾“å‡ºåŸºç¡€ç›®å½•è·¯å¾„
        """
        print("ğŸš€ å¼€å§‹æ‰¹é‡æ£€æµ‹æ–‡ä»¶å¤¹å›¾ç‰‡")
        print("=" * 60)

        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']

        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        input_path = Path(input_folder)

        for ext in image_extensions:
            image_files.extend(glob.glob(str(input_path / ext)))
            image_files.extend(glob.glob(str(input_path / ext.upper())))

        if not image_files:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ {input_folder} ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
            return []

        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_base_dir}")

        # åˆ›å»ºè¾“å‡ºåŸºç¡€ç›®å½•
        output_base_path = Path(output_base_dir)
        output_base_path.mkdir(parents=True, exist_ok=True)

        # æ‰¹é‡æ£€æµ‹ç»Ÿè®¡
        batch_results = {
            'total_images': len(image_files),
            'processed_images': 0,
            'failed_images': 0,
            'total_detections': 0,
            'total_dynamic': 0,
            'total_static': 0,
            'total_sam_success': 0,
            'processing_time': 0,
            'results_per_image': []
        }

        start_time = datetime.now()

        # å¤„ç†æ¯å¼ å›¾ç‰‡
        for i, image_path in enumerate(image_files, 1):
            image_name = Path(image_path).stem
            print(f"\nğŸ” å¤„ç†å›¾ç‰‡ [{i}/{len(image_files)}]: {image_name}")
            print("-" * 50)

            try:
                # ä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºæ–‡ä»¶å¤¹
                image_output_dir = output_base_path / image_name
                image_output_dir.mkdir(parents=True, exist_ok=True)

                # æ£€æµ‹å½“å‰å›¾ç‰‡
                detections = self.detect_objects_with_sam(image_path, str(image_output_dir))

                # ç»Ÿè®¡å½“å‰å›¾ç‰‡çš„æ£€æµ‹ç»“æœ
                dynamic_count = len([d for d in detections if d['type'] == 'dynamic'])
                static_count = len([d for d in detections if d['type'] == 'static'])
                sam_count = len([d for d in detections if d.get('sam_mask') is not None])

                # ä¿å­˜å½“å‰å›¾ç‰‡çš„æ£€æµ‹ç»“æœåˆ°JSON
                image_result = {
                    'image_name': image_name,
                    'image_path': image_path,
                    'output_dir': str(image_output_dir),
                    'total_detections': len(detections),
                    'dynamic_count': dynamic_count,
                    'static_count': static_count,
                    'sam_success_count': sam_count,
                    'detections': []
                }

                # è¯¦ç»†æ£€æµ‹ç»“æœ
                for det in detections:
                    detection_info = {
                        'phrase': det['phrase'],
                        'type': det['type'],
                        'confidence': float(det['confidence']),
                        'bbox': det['box_xyxy'].cpu().numpy().tolist(),
                        'sam_success': det.get('sam_success', False)
                    }
                    image_result['detections'].append(detection_info)

                # ä¿å­˜JSONç»“æœ
                json_path = image_output_dir / f"{image_name}_detection_results.json"
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(image_result, f, indent=2, ensure_ascii=False)

                # æ›´æ–°æ‰¹é‡ç»Ÿè®¡
                batch_results['processed_images'] += 1
                batch_results['total_detections'] += len(detections)
                batch_results['total_dynamic'] += dynamic_count
                batch_results['total_static'] += static_count
                batch_results['total_sam_success'] += sam_count
                batch_results['results_per_image'].append(image_result)

                print(f"âœ… {image_name} å¤„ç†å®Œæˆ:")
                print(f"   ğŸ“Š æ£€æµ‹æ€»æ•°: {len(detections)}")
                print(f"   ğŸ”´ åŠ¨æ€ç‰©ä½“: {dynamic_count}")
                print(f"   ğŸŸ¢ é™æ€ç‰©ä½“: {static_count}")
                print(f"   ğŸ¯ SAMæˆåŠŸ: {sam_count}")
                print(f"   ğŸ’¾ ç»“æœä¿å­˜è‡³: {image_output_dir}")

            except Exception as e:
                print(f"âŒ å¤„ç† {image_name} æ—¶å‡ºé”™: {e}")
                batch_results['failed_images'] += 1
                continue

        # è®¡ç®—æ€»å¤„ç†æ—¶é—´
        end_time = datetime.now()
        batch_results['processing_time'] = (end_time - start_time).total_seconds()

        # ä¿å­˜æ‰¹é‡å¤„ç†æ€»ç»“æŠ¥å‘Š
        self._save_batch_summary(batch_results, output_base_path, start_time, end_time)

        # åˆ›å»ºæ‰¹é‡å¯è§†åŒ–æ¦‚è§ˆ
        self._create_batch_overview(batch_results, output_base_path)

        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰¹é‡æ£€æµ‹å®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   ğŸ“· æ€»å›¾ç‰‡æ•°: {batch_results['total_images']}")
        print(f"   âœ… æˆåŠŸå¤„ç†: {batch_results['processed_images']}")
        print(f"   âŒ å¤„ç†å¤±è´¥: {batch_results['failed_images']}")
        print(f"   ğŸ” æ€»æ£€æµ‹æ•°: {batch_results['total_detections']}")
        print(f"   ğŸ”´ æ€»åŠ¨æ€ç‰©ä½“: {batch_results['total_dynamic']}")
        print(f"   ğŸŸ¢ æ€»é™æ€ç‰©ä½“: {batch_results['total_static']}")
        print(f"   ğŸ¯ æ€»SAMæˆåŠŸ: {batch_results['total_sam_success']}")
        print(f"   â±ï¸  æ€»è€—æ—¶: {batch_results['processing_time']:.2f} ç§’")
        print(f"   ğŸ“ ç»“æœç›®å½•: {output_base_path}")

        return batch_results

    def _save_batch_summary(self, batch_results, output_base_path, start_time, end_time):
        """ä¿å­˜æ‰¹é‡å¤„ç†çš„æ€»ç»“æŠ¥å‘Š"""

        # ä¿å­˜è¯¦ç»†çš„JSONæŠ¥å‘Š
        summary_json = {
            **batch_results,
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'average_time_per_image': batch_results['processing_time'] / max(1, batch_results['processed_images']),
            'success_rate': batch_results['processed_images'] / batch_results['total_images'] * 100
        }

        json_summary_path = output_base_path / "batch_processing_summary.json"
        with open(json_summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary_json, f, indent=2, ensure_ascii=False)

        # åˆ›å»ºå¯è¯»çš„æ–‡æœ¬æŠ¥å‘Š
        txt_summary_path = output_base_path / "batch_processing_report.txt"
        with open(txt_summary_path, 'w', encoding='utf-8') as f:
            f.write("ğŸš€ æ‰¹é‡å›¾ç‰‡æ£€æµ‹å¤„ç†æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(
                f"å¤„ç†æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')} - {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»å¤„ç†æ—¶é•¿: {batch_results['processing_time']:.2f} ç§’\n")
            f.write(
                f"å¹³å‡æ¯å¼ å›¾ç‰‡: {batch_results['processing_time'] / max(1, batch_results['processed_images']):.2f} ç§’\n\n")

            f.write("ğŸ“Š å¤„ç†ç»Ÿè®¡:\n")
            f.write(f"  æ€»å›¾ç‰‡æ•°é‡: {batch_results['total_images']}\n")
            f.write(f"  æˆåŠŸå¤„ç†: {batch_results['processed_images']}\n")
            f.write(f"  å¤„ç†å¤±è´¥: {batch_results['failed_images']}\n")
            f.write(f"  æˆåŠŸç‡: {batch_results['processed_images'] / batch_results['total_images'] * 100:.1f}%\n\n")

            f.write("ğŸ” æ£€æµ‹ç»Ÿè®¡:\n")
            f.write(f"  æ€»æ£€æµ‹æ•°é‡: {batch_results['total_detections']}\n")
            f.write(f"  åŠ¨æ€ç‰©ä½“: {batch_results['total_dynamic']}\n")
            f.write(f"  é™æ€ç‰©ä½“: {batch_results['total_static']}\n")
            f.write(f"  SAMåˆ†å‰²æˆåŠŸ: {batch_results['total_sam_success']}\n")
            f.write(
                f"  å¹³å‡æ¯å¼ å›¾ç‰‡æ£€æµ‹æ•°: {batch_results['total_detections'] / max(1, batch_results['processed_images']):.1f}\n\n")

            f.write("ğŸ“· å„å›¾ç‰‡è¯¦ç»†ç»“æœ:\n")
            f.write("-" * 50 + "\n")
            for result in batch_results['results_per_image']:
                f.write(f"å›¾ç‰‡: {result['image_name']}\n")
                f.write(
                    f"  æ€»æ£€æµ‹: {result['total_detections']} (åŠ¨æ€: {result['dynamic_count']}, é™æ€: {result['static_count']})\n")
                f.write(f"  SAMæˆåŠŸ: {result['sam_success_count']}\n")
                f.write(f"  è¾“å‡ºç›®å½•: {result['output_dir']}\n\n")

        print(f"ğŸ“‹ æ‰¹é‡å¤„ç†æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   ğŸ“„ JSONæŠ¥å‘Š: {json_summary_path}")
        print(f"   ğŸ“„ æ–‡æœ¬æŠ¥å‘Š: {txt_summary_path}")

    def _create_batch_overview(self, batch_results, output_base_path):
        """åˆ›å»ºæ‰¹é‡å¤„ç†çš„å¯è§†åŒ–æ¦‚è§ˆ"""
        try:
            import matplotlib.pyplot as plt
            import numpy as np

            # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
            plt.rcParams['axes.unicode_minus'] = False

            # åˆ›å»ºæ¦‚è§ˆå›¾
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('æ‰¹é‡å›¾ç‰‡æ£€æµ‹å¤„ç†æ¦‚è§ˆ', fontsize=16, fontweight='bold')

            # 1. å¤„ç†æˆåŠŸç‡é¥¼å›¾
            success_data = [batch_results['processed_images'], batch_results['failed_images']]
            success_labels = ['æˆåŠŸå¤„ç†', 'å¤„ç†å¤±è´¥']
            colors1 = ['#2ecc71', '#e74c3c']
            ax1.pie(success_data, labels=success_labels, autopct='%1.1f%%', colors=colors1, startangle=90)
            ax1.set_title('å¤„ç†æˆåŠŸç‡')

            # 2. æ£€æµ‹ç±»å‹åˆ†å¸ƒ
            detection_data = [batch_results['total_dynamic'], batch_results['total_static']]
            detection_labels = ['åŠ¨æ€ç‰©ä½“', 'é™æ€ç‰©ä½“']
            colors2 = ['#e67e22', '#3498db']
            ax2.pie(detection_data, labels=detection_labels, autopct='%1.1f%%', colors=colors2, startangle=90)
            ax2.set_title('æ£€æµ‹ç‰©ä½“ç±»å‹åˆ†å¸ƒ')

            # 3. æ¯å¼ å›¾ç‰‡æ£€æµ‹æ•°é‡åˆ†å¸ƒ
            if batch_results['results_per_image']:
                detection_counts = [r['total_detections'] for r in batch_results['results_per_image']]
                ax3.hist(detection_counts, bins=10, color='#9b59b6', alpha=0.7, edgecolor='black')
                ax3.set_xlabel('æ£€æµ‹æ•°é‡')
                ax3.set_ylabel('å›¾ç‰‡æ•°é‡')
                ax3.set_title('æ¯å¼ å›¾ç‰‡æ£€æµ‹æ•°é‡åˆ†å¸ƒ')
                ax3.grid(True, alpha=0.3)

            # 4. SAMæˆåŠŸç‡
            if batch_results['total_detections'] > 0:
                sam_success_rate = batch_results['total_sam_success'] / batch_results['total_detections'] * 100
                sam_fail_rate = 100 - sam_success_rate
                sam_data = [sam_success_rate, sam_fail_rate]
                sam_labels = ['SAMæˆåŠŸ', 'SAMå¤±è´¥']
                colors4 = ['#1abc9c', '#95a5a6']
                ax4.pie(sam_data, labels=sam_labels, autopct='%1.1f%%', colors=colors4, startangle=90)
                ax4.set_title('SAMåˆ†å‰²æˆåŠŸç‡')
            else:
                ax4.text(0.5, 0.5, 'æ— æ£€æµ‹æ•°æ®', ha='center', va='center', transform=ax4.transAxes)
                ax4.set_title('SAMåˆ†å‰²æˆåŠŸç‡')

            plt.tight_layout()

            # ä¿å­˜æ¦‚è§ˆå›¾
            overview_path = output_base_path / "batch_processing_overview.png"
            plt.savefig(overview_path, dpi=300, bbox_inches='tight')
            plt.close()

            print(f"   ğŸ“Š å¯è§†åŒ–æ¦‚è§ˆ: {overview_path}")

        except ImportError:
            print("   âš ï¸  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–æ¦‚è§ˆç”Ÿæˆ")
        except Exception as e:
            print(f"   âš ï¸  ç”Ÿæˆå¯è§†åŒ–æ¦‚è§ˆæ—¶å‡ºé”™: {e}")

    # ================================
    # åŸæœ‰çš„æ‰€æœ‰æ–¹æ³•ä¿æŒä¸å˜
    # ================================

    def create_mask_overlay_on_original(self, image_path, detections, save_dir="./", image_name="result"):
        """åœ¨åŸå›¾ä¸Šåˆ›å»ºmaskå åŠ å¯è§†åŒ–ï¼ˆä¿æŒåŸå›¾èƒŒæ™¯ï¼‰"""

        # è¯»å–åŸå›¾
        original_image = cv2.imread(image_path)
        if original_image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None

        h, w, _ = original_image.shape
        base_name = os.path.splitext(image_name)[0]

        # åˆ›å»ºä¿å­˜ç›®å½•
        overlay_dir = os.path.join(save_dir, "mask_overlays")
        os.makedirs(overlay_dir, exist_ok=True)

        print("ğŸ¨ åœ¨åŸå›¾ä¸Šåˆ›å»ºmaskå åŠ å¯è§†åŒ–...")

        # åˆ›å»ºä¸åŒç‰ˆæœ¬çš„å åŠ å›¾åƒï¼ˆéƒ½åŸºäºåŸå›¾ï¼‰
        complete_overlay = original_image.copy()
        dynamic_overlay = original_image.copy()
        static_overlay = original_image.copy()

        # é€æ˜åº¦è®¾ç½®
        alpha_objects = 0.4

        # ç»Ÿè®¡è®¡æ•°
        dynamic_count = 0
        static_count = 0

        # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
        for det in detections:
            obj_type = det['type']
            phrase = det['phrase']
            confidence = det['confidence']
            sam_mask = det.get('sam_mask')
            box_xyxy = det['box_xyxy']

            # è·å–é¢œè‰²
            color = self.get_color_for_class(phrase, is_dynamic=(obj_type == 'dynamic'))

            # åˆ›å»ºmask
            if sam_mask is not None:
                # ä½¿ç”¨SAMç²¾ç¡®mask
                mask_bool = sam_mask.astype(bool)
            else:
                # ä½¿ç”¨è¾¹ç•Œæ¡†ä½œä¸ºmask
                x1, y1, x2, y2 = box_xyxy.cpu().numpy().astype(int)
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)

                mask_bool = np.zeros((h, w), dtype=bool)
                mask_bool[y1:y2, x1:x2] = True

            # åˆ›å»ºå½©è‰²å åŠ å±‚
            overlay_layer = np.zeros_like(original_image)
            overlay_layer[mask_bool] = color

            # åœ¨ç›¸åº”çš„å›¾åƒä¸Šå åŠ ï¼ˆä¿æŒåŸå›¾èƒŒæ™¯ï¼‰
            complete_overlay = cv2.addWeighted(complete_overlay, 1 - alpha_objects, overlay_layer, alpha_objects, 0)

            if obj_type == 'dynamic':
                dynamic_overlay = cv2.addWeighted(dynamic_overlay, 1 - alpha_objects, overlay_layer, alpha_objects, 0)
                dynamic_count += 1
            else:
                static_overlay = cv2.addWeighted(static_overlay, 1 - alpha_objects, overlay_layer, alpha_objects, 0)
                static_count += 1

            # åœ¨å®Œæ•´å åŠ å›¾ä¸Šæ·»åŠ è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
            # x1, y1, x2, y2 = box_xyxy.cpu().numpy().astype(int)
            # thickness = 3 if obj_type == 'dynamic' else 2
            # line_color = tuple(int(c * 0.8) for c in color)
            #
            # cv2.rectangle(complete_overlay, (x1, y1), (x2, y2), line_color, thickness)

            # æ·»åŠ æ ‡ç­¾
            label = f"[{'D' if obj_type == 'dynamic' else 'S'}] {phrase}: {confidence:.2f}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.6
            font_thickness = 2

            (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, font_thickness)

            # æ–‡æœ¬èƒŒæ™¯
            # bg_color = tuple(int(c * 0.6) for c in color)
            # cv2.rectangle(complete_overlay, (x1, y1 - text_height - 10),
            #               (x1 + text_width + 10, y1), bg_color, -1)

            # æ–‡æœ¬
            # cv2.putText(complete_overlay, label, (x1 + 5, y1 - 5),
            #             font, font_scale, (255, 255, 255), font_thickness)

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        self._add_overlay_statistics(complete_overlay, dynamic_count, static_count, "COMPLETE OVERLAY")
        self._add_overlay_statistics(dynamic_overlay, dynamic_count, 0, "DYNAMIC OBJECTS")
        self._add_overlay_statistics(static_overlay, 0, static_count, "STATIC OBJECTS")

        # ä¿å­˜ç»“æœ
        complete_path = os.path.join(overlay_dir, f"{base_name}_complete_overlay.jpg")
        dynamic_path = os.path.join(overlay_dir, f"{base_name}_dynamic_overlay.jpg")
        static_path = os.path.join(overlay_dir, f"{base_name}_static_overlay.jpg")

        cv2.imwrite(complete_path, complete_overlay)
        cv2.imwrite(dynamic_path, dynamic_overlay)
        cv2.imwrite(static_path, static_overlay)

        # åˆ›å»º2x2å¯¹æ¯”ç½‘æ ¼
        self._create_overlay_grid(original_image, dynamic_overlay, static_overlay,
                                  complete_overlay, overlay_dir, base_name)

        print(f"âœ… Maskå åŠ å¯è§†åŒ–å®Œæˆ:")
        print(f"   ğŸŒˆ å®Œæ•´å åŠ : {complete_path}")
        print(f"   ğŸ”´ åŠ¨æ€å åŠ : {dynamic_path}")
        print(f"   ğŸŸ¢ é™æ€å åŠ : {static_path}")

        return complete_overlay, dynamic_overlay, static_overlay

    def _add_overlay_statistics(self, image, dynamic_count, static_count, title):
        """ä¸ºå åŠ å›¾åƒæ·»åŠ ç»Ÿè®¡ä¿¡æ¯"""
        h, w = image.shape[:2]

        stats_lines = [
            title,
            f"Dynamic: {dynamic_count}",
            f"Static: {static_count}",
            f"Total: {dynamic_count + static_count}"
        ]

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        font_thickness = 2
        line_height = 30

        # è®¡ç®—èƒŒæ™¯å¤§å°
        max_width = 0
        for line in stats_lines:
            (text_width, _), _ = cv2.getTextSize(line, font, font_scale, font_thickness)
            max_width = max(max_width, text_width)

        bg_height = len(stats_lines) * line_height + 20

        # åŠé€æ˜èƒŒæ™¯
        # overlay = image.copy()
        # cv2.rectangle(overlay, (10, 10), (max_width + 30, bg_height), (0, 0, 0), -1)
        # cv2.addWeighted(image, 0.7, overlay, 0.3, 0, image)

        # è¾¹æ¡†
        # cv2.rectangle(image, (10, 10), (max_width + 30, bg_height), (255, 255, 255), 2)

        # æ–‡æœ¬
        # for i, line in enumerate(stats_lines):
        #     y = 35 + i * line_height
        #     color = (255, 255, 255) if i == 0 else (0, 255, 255)
        #     cv2.putText(image, line, (20, y), font, font_scale, color, font_thickness)

    def _create_overlay_grid(self, original, dynamic_overlay, static_overlay, complete_overlay, save_dir, base_name):
        """åˆ›å»º2x2å¯¹æ¯”ç½‘æ ¼"""

        # è°ƒæ•´æ‰€æœ‰å›¾åƒåˆ°ç›¸åŒå¤§å°
        h, w = original.shape[:2]
        target_size = (w // 2, h // 2)  # ç¼©å°ä¸€åŠ

        # è°ƒæ•´å¤§å°å¹¶æ·»åŠ æ ‡é¢˜
        def resize_and_add_title(img, title):
            resized = cv2.resize(img, target_size)
            cv2.putText(resized, title, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                        0.8, (255, 255, 255), 3)
            cv2.putText(resized, title, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                        0.8, (0, 0, 0), 2)
            return resized

        orig_small = resize_and_add_title(original, "Original")
        dyn_small = resize_and_add_title(dynamic_overlay, "Dynamic Objects")
        stat_small = resize_and_add_title(static_overlay, "Static Objects")
        comp_small = resize_and_add_title(complete_overlay, "Complete")

        # æ‹¼æ¥
        top_row = np.hstack([orig_small, dyn_small])
        bottom_row = np.hstack([stat_small, comp_small])
        grid = np.vstack([top_row, bottom_row])

        # ä¿å­˜ç½‘æ ¼
        grid_path = os.path.join(save_dir, f"{base_name}_overlay_grid.jpg")
        cv2.imwrite(grid_path, grid)
        print(f"   ğŸ“Š å¯¹æ¯”ç½‘æ ¼: {grid_path}")

        return grid

    def create_prompts(self):
        """åˆ›å»ºæ£€æµ‹æç¤ºè¯"""
        # åŠ¨æ€ç‰©ä½“æç¤ºè¯
        dynamic_prompt = " . ".join(
            self.dynamic_objects["primary"] +
            self.dynamic_objects["secondary"][:3]
        ) + " ."

        # é™æ€ç‰©ä½“æç¤ºè¯
        static_prompt = " . ".join(
            self.static_objects["primary"] +
            self.static_objects["secondary"][:3]
        ) + " ."

        return dynamic_prompt, static_prompt

    def classify_detection(self, phrase):
        """åˆ†ç±»æ£€æµ‹ç»“æœæ˜¯åŠ¨æ€è¿˜æ˜¯é™æ€"""
        phrase_lower = phrase.lower().strip()

        # æ£€æŸ¥åŠ¨æ€ç‰©ä½“
        all_dynamic = (self.dynamic_objects["primary"] +
                       self.dynamic_objects["secondary"] +
                       self.dynamic_objects["specific"])

        for dynamic_word in all_dynamic:
            if dynamic_word.lower() in phrase_lower:
                return "dynamic"

        # æ£€æŸ¥é™æ€ç‰©ä½“
        all_static = (self.static_objects["primary"] +
                      self.static_objects["secondary"] +
                      self.static_objects["specific"])

        for static_word in all_static:
            if static_word.lower() in phrase_lower:
                return "static"

        # é»˜è®¤åˆ†ç±»é€»è¾‘
        moving_keywords = ["car", "truck", "bus", "person", "bike", "vehicle", "people"]
        static_keywords = ["building", "tree", "road", "wall", "house", "street"]

        if any(keyword in phrase_lower for keyword in moving_keywords):
            return "dynamic"
        elif any(keyword in phrase_lower for keyword in static_keywords):
            return "static"

        return "unknown"

    def detect_objects_with_sam(self, image_path, save_dir="./detection_results"):
        """æ£€æµ‹å›¾åƒä¸­çš„åŠ¨æ€å’Œé™æ€ç‰©ä½“ï¼Œå¹¶ä½¿ç”¨SAMè¿›è¡Œç²¾ç¡®åˆ†å‰²"""
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        os.makedirs(os.path.join(save_dir, "masks"), exist_ok=True)

        # åŠ è½½å›¾åƒ
        print(f"ğŸ“· åŠ è½½å›¾åƒ: {image_path}")
        image_source, image = load_image(image_path)
        h, w, _ = image_source.shape
        print(f"   å›¾åƒå°ºå¯¸: {w}x{h}")

        # è®¾ç½®SAMå›¾åƒ
        if self.sam_predictor:
            self.sam_predictor.set_image(image_source)
            print("ğŸ¯ SAMå›¾åƒè®¾ç½®å®Œæˆ")

        # åˆ›å»ºæç¤ºè¯
        dynamic_prompt, static_prompt = self.create_prompts()
        print(f"ğŸ¯ åŠ¨æ€ç‰©ä½“æç¤ºè¯: {dynamic_prompt[:50]}...")
        print(f"ğŸ—ï¸  é™æ€ç‰©ä½“æç¤ºè¯: {static_prompt[:50]}...")

        all_detections = []

        # æ£€æµ‹åŠ¨æ€ç‰©ä½“
        print("\nğŸ” æ£€æµ‹åŠ¨æ€ç‰©ä½“...")
        dynamic_detections = self._detect_with_prompt_and_sam(image, dynamic_prompt, "dynamic", w, h)
        all_detections.extend(dynamic_detections)

        # æ£€æµ‹é™æ€ç‰©ä½“
        print("ğŸ” æ£€æµ‹é™æ€ç‰©ä½“...")
        static_detections = self._detect_with_prompt_and_sam(image, static_prompt, "static", w, h)
        all_detections.extend(static_detections)

        # åå¤„ç†å’Œå»é‡
        filtered_detections = self._post_process_detections_with_sam(all_detections, w, h)

        # åˆ†ç±»ç»Ÿè®¡
        dynamic_count = len([d for d in filtered_detections if d['type'] == 'dynamic'])
        static_count = len([d for d in filtered_detections if d['type'] == 'static'])
        sam_count = len([d for d in filtered_detections if d.get('sam_mask') is not None])

        print(f"\nğŸ“Š æ£€æµ‹ç»“æœç»Ÿè®¡:")
        print(f"   åŠ¨æ€ç‰©ä½“: {dynamic_count} ä¸ª")
        print(f"   é™æ€ç‰©ä½“: {static_count} ä¸ª")
        print(f"   æ€»è®¡: {len(filtered_detections)} ä¸ª")
        print(f"   SAMåˆ†å‰²æˆåŠŸ: {sam_count} ä¸ª")

        # ğŸ¨ åˆ›å»ºå¯è§†åŒ–
        self._create_comprehensive_visualization(image_source, filtered_detections, save_dir,
                                                 os.path.basename(image_path))

        # ğŸ¨ åˆ›å»ºåŸç‰ˆmaskå åŠ å¯è§†åŒ–ï¼ˆåœ¨åŸå›¾ä¸Šï¼‰
        print("\nğŸ¨ åˆ›å»ºmaskå åŠ å¯è§†åŒ–...")
        overlay_results = self.create_mask_overlay_on_original(
            image_path, filtered_detections, save_dir, os.path.basename(image_path)
        )

        # ğŸ¨ åˆ›å»ºå¢å¼ºçš„maskå åŠ å¯è§†åŒ–ï¼ˆæ–°å¢ï¼‰
        print("\nğŸ¨ åˆ›å»ºå¢å¼ºmaskå åŠ å¯è§†åŒ–...")
        enhanced_results = self.create_enhanced_mask_overlay(
            image_path, filtered_detections, save_dir, os.path.basename(image_path)
        )

        # ğŸ¨ åˆ›å»ºçº¯è½®å»“å åŠ å¯è§†åŒ–ï¼ˆæ–°å¢ï¼‰
        print("ğŸ¨ åˆ›å»ºè½®å»“å åŠ å¯è§†åŒ–...")
        contour_result = self.create_contour_only_overlay(
            image_path, filtered_detections, save_dir, os.path.basename(image_path)
        )

        print("\nâœ… æ‰€æœ‰å¯è§†åŒ–å®Œæˆ!")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶å¤¹:")
        print("   ğŸ“‚ mask_overlays/ - åŸç‰ˆmaskå åŠ ")
        print("   ğŸ“‚ enhanced_overlays/ - å¢å¼ºmaskå åŠ  (æ¨è)")
        print("   ğŸ“‚ contour_overlays/ - çº¯è½®å»“å åŠ ")
        print("   ğŸ“‚ masks/ - å•ç‹¬çš„maskæ–‡ä»¶")

        return filtered_detections

    # æ”¹è¿›çš„maskåœ¨åŸå›¾ä¸Šçš„å¯è§†åŒ–æ–¹æ³•

    def create_enhanced_mask_overlay(self, image_path, detections, save_dir="./", image_name="result"):
        """æ”¹è¿›çš„åœ¨åŸå›¾ä¸Šåˆ›å»ºmaskå åŠ å¯è§†åŒ–ï¼ˆæ›´æ¸…æ™°çš„åŸå›¾èƒŒæ™¯ï¼‰"""

        # è¯»å–åŸå›¾
        original_image = cv2.imread(image_path)
        if original_image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None

        h, w, _ = original_image.shape
        base_name = os.path.splitext(image_name)[0]

        # åˆ›å»ºä¿å­˜ç›®å½•
        overlay_dir = os.path.join(save_dir, "enhanced_overlays")
        os.makedirs(overlay_dir, exist_ok=True)

        print("ğŸ¨ åˆ›å»ºæ”¹è¿›çš„maskå åŠ å¯è§†åŒ–...")

        # åˆ›å»ºä¸åŒç‰ˆæœ¬çš„å åŠ å›¾åƒï¼ˆéƒ½åŸºäºåŸå›¾ï¼‰
        complete_overlay = original_image.copy()
        dynamic_overlay = original_image.copy()
        static_overlay = original_image.copy()

        # ğŸ¯ å…³é”®æ”¹è¿›ï¼šæ›´å¥½çš„é€æ˜åº¦è®¾ç½®
        alpha_mask = 0.3  # maské€æ˜åº¦é™ä½ï¼Œè®©åŸå›¾æ›´æ¸…æ™°
        alpha_original = 0.9  # åŸå›¾é€æ˜åº¦æé«˜

        # ğŸ¨ æ”¹è¿›çš„é¢œè‰²æ–¹æ¡ˆï¼ˆæ›´äº®çš„é¢œè‰²ï¼‰
        enhanced_dynamic_colors = {
            'person': [0, 100, 255],  # äº®çº¢è‰²
            'car': [0, 200, 255],  # äº®æ©™è‰²
            'truck': [0, 255, 255],  # é»„è‰²
            'bus': [128, 0, 255],  # ç´«è‰²
            'bicycle': [255, 100, 255],  # äº®ç²‰è‰²
            'motorcycle': [255, 150, 0],  # è“æ©™è‰²
        }

        enhanced_static_colors = {
            'building': [200, 200, 100],  # äº®æ©„æ¦„è‰²
            'tree': [100, 255, 100],  # äº®ç»¿è‰²
            'road': [150, 150, 150],  # äº®ç°è‰²
            'wall': [180, 180, 180],  # æµ…ç°è‰²
            'fence': [200, 200, 0],  # äº®é»„è‰²
            'pole': [150, 100, 50],  # äº®æ£•è‰²
        }

        # ç»Ÿè®¡è®¡æ•°
        dynamic_count = 0
        static_count = 0

        # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
        for det in detections:
            obj_type = det['type']
            phrase = det['phrase']
            confidence = det['confidence']
            sam_mask = det.get('sam_mask')
            box_xyxy = det['box_xyxy']

            # ğŸ¨ è·å–å¢å¼ºçš„é¢œè‰²
            phrase_lower = phrase.lower()
            if obj_type == 'dynamic':
                color = None
                for key, enhanced_color in enhanced_dynamic_colors.items():
                    if key in phrase_lower:
                        color = enhanced_color
                        break
                if color is None:
                    color = self.get_color_for_class(phrase, is_dynamic=True)
                    # å¢äº®é¢œè‰²
                    color = [min(255, int(c * 1.5)) for c in color]
            else:
                color = None
                for key, enhanced_color in enhanced_static_colors.items():
                    if key in phrase_lower:
                        color = enhanced_color
                        break
                if color is None:
                    color = self.get_color_for_class(phrase, is_dynamic=False)
                    # å¢äº®é¢œè‰²
                    color = [min(255, int(c * 1.3)) for c in color]

            # åˆ›å»ºmask
            if sam_mask is not None:
                # ä½¿ç”¨SAMç²¾ç¡®mask
                mask_bool = sam_mask.astype(bool)
            else:
                # ä½¿ç”¨è¾¹ç•Œæ¡†ä½œä¸ºmask
                x1, y1, x2, y2 = box_xyxy.cpu().numpy().astype(int)
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)

                mask_bool = np.zeros((h, w), dtype=bool)
                mask_bool[y1:y2, x1:x2] = True

            # ğŸ¯ æ”¹è¿›çš„å åŠ æ–¹æ³•ï¼šåªå¯¹maskåŒºåŸŸè¿›è¡Œæ··åˆ
            mask_area = np.zeros_like(original_image)
            mask_area[mask_bool] = color

            # åªåœ¨maskåŒºåŸŸè¿›è¡Œé¢œè‰²æ··åˆï¼Œä¿æŒåŸå›¾å…¶ä»–åŒºåŸŸä¸å˜
            mask_indices = np.where(mask_bool)
            if len(mask_indices[0]) > 0:
                # åœ¨å®Œæ•´å åŠ å›¾ä¸Šåº”ç”¨
                complete_overlay[mask_indices] = (
                        alpha_original * complete_overlay[mask_indices] +
                        alpha_mask * np.array(color)
                ).astype(np.uint8)

                if obj_type == 'dynamic':
                    dynamic_overlay[mask_indices] = (
                            alpha_original * dynamic_overlay[mask_indices] +
                            alpha_mask * np.array(color)
                    ).astype(np.uint8)
                    dynamic_count += 1
                else:
                    static_overlay[mask_indices] = (
                            alpha_original * static_overlay[mask_indices] +
                            alpha_mask * np.array(color)
                    ).astype(np.uint8)
                    static_count += 1

            # ğŸ¯ æ·»åŠ è½®å»“çº¿å¢å¼ºå¯è§æ€§
            if sam_mask is not None:
                # æ‰¾åˆ°maskè½®å»“
                contours, _ = cv2.findContours(sam_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                # ç»˜åˆ¶è½®å»“
                cv2.drawContours(complete_overlay, contours, -1, color, 2)
                if obj_type == 'dynamic':
                    cv2.drawContours(dynamic_overlay, contours, -1, color, 2)
                else:
                    cv2.drawContours(static_overlay, contours, -1, color, 2)

            # æ·»åŠ è¾¹ç•Œæ¡†ï¼ˆç»†çº¿ï¼‰
            # x1, y1, x2, y2 = box_xyxy.cpu().numpy().astype(int)
            # thickness = 2 if obj_type == 'dynamic' else 1
            # line_color = tuple(int(c * 0.8) for c in color)
            #
            # cv2.rectangle(complete_overlay, (x1, y1), (x2, y2), line_color, thickness)

            # ğŸ¯ æ”¹è¿›çš„æ ‡ç­¾æ˜¾ç¤º
            label = f"{phrase}: {confidence:.2f}"
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.5
            font_thickness = 1

            (text_width, text_height), baseline = cv2.getTextSize(label, font, font_scale, font_thickness)

            # åŠé€æ˜æ–‡æœ¬èƒŒæ™¯
            # overlay_bg = complete_overlay.copy()
            # cv2.rectangle(overlay_bg, (x1, y1 - text_height - 8),
            #               (x1 + text_width + 8, y1), color, -1)
            # cv2.addWeighted(complete_overlay, 0.7, overlay_bg, 0.3, 0, complete_overlay)

            # ç™½è‰²æ–‡æœ¬
            # cv2.putText(complete_overlay, label, (x1 + 4, y1 - 4),
            #             font, font_scale, (255, 255, 255), font_thickness)

        # æ·»åŠ æ”¹è¿›çš„ç»Ÿè®¡ä¿¡æ¯
        self._add_enhanced_statistics(complete_overlay, dynamic_count, static_count, "ENHANCED OVERLAY")
        self._add_enhanced_statistics(dynamic_overlay, dynamic_count, 0, "DYNAMIC OBJECTS")
        self._add_enhanced_statistics(static_overlay, 0, static_count, "STATIC OBJECTS")

        # ä¿å­˜ç»“æœ
        complete_path = os.path.join(overlay_dir, f"{base_name}_enhanced_complete.jpg")
        dynamic_path = os.path.join(overlay_dir, f"{base_name}_enhanced_dynamic.jpg")
        static_path = os.path.join(overlay_dir, f"{base_name}_enhanced_static.jpg")

        cv2.imwrite(complete_path, complete_overlay)
        cv2.imwrite(dynamic_path, dynamic_overlay)
        cv2.imwrite(static_path, static_overlay)

        # ğŸ¯ åˆ›å»ºåŸå›¾å¯¹æ¯”
        self._create_before_after_comparison(original_image, complete_overlay, overlay_dir, base_name)

        print(f"âœ… å¢å¼ºmaskå åŠ å¯è§†åŒ–å®Œæˆ:")
        print(f"   ğŸŒˆ å¢å¼ºå®Œæ•´: {complete_path}")
        print(f"   ğŸ”´ å¢å¼ºåŠ¨æ€: {dynamic_path}")
        print(f"   ğŸŸ¢ å¢å¼ºé™æ€: {static_path}")

        return complete_overlay, dynamic_overlay, static_overlay

    def _add_enhanced_statistics(self, image, dynamic_count, static_count, title):
        """æ·»åŠ å¢å¼ºçš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ›´æ¸…æ™°çš„æ˜¾ç¤ºï¼‰"""
        h, w = image.shape[:2]

        stats_lines = [
            title,
            f"Dynamic: {dynamic_count}",
            f"Static: {static_count}",
            f"Total: {dynamic_count + static_count}"
        ]

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        font_thickness = 2
        line_height = 25

        # è®¡ç®—èƒŒæ™¯å¤§å°
        max_width = 0
        for line in stats_lines:
            (text_width, _), _ = cv2.getTextSize(line, font, font_scale, font_thickness)
            max_width = max(max_width, text_width)

        bg_height = len(stats_lines) * line_height + 15

        # ğŸ¯ æ›´æ¸…æ™°çš„åŠé€æ˜èƒŒæ™¯
        # overlay = image.copy()
        # cv2.rectangle(overlay, (10, 10), (max_width + 25, bg_height), (0, 0, 0), -1)
        # cv2.addWeighted(image, 0.8, overlay, 0.2, 0, image)  # é™ä½èƒŒæ™¯é€æ˜åº¦

        # äº®è‰²è¾¹æ¡†
        # cv2.rectangle(image, (10, 10), (max_width + 25, bg_height), (255, 255, 255), 2)

        # æ–‡æœ¬
        # for i, line in enumerate(stats_lines):
        #     y = 30 + i * line_height
        #     color = (255, 255, 255) if i == 0 else (0, 255, 255)
        #     cv2.putText(image, line, (15, y), font, font_scale, color, font_thickness)

    def _create_before_after_comparison(self, original, overlay_result, save_dir, base_name):
        """åˆ›å»ºåŸå›¾ä¸å åŠ ç»“æœçš„å¯¹æ¯”"""

        # è°ƒæ•´å¤§å°
        h, w = original.shape[:2]
        target_size = (w // 2, h // 2)

        orig_small = cv2.resize(original, target_size)
        overlay_small = cv2.resize(overlay_result, target_size)

        # æ·»åŠ æ ‡é¢˜
        # cv2.putText(orig_small, "Original", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
        #             1.0, (255, 255, 255), 3)
        # cv2.putText(orig_small, "Original", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
        #             1.0, (0, 0, 0), 2)
        #
        # cv2.putText(overlay_small, "With Masks", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
        #             1.0, (255, 255, 255), 3)
        # cv2.putText(overlay_small, "With Masks", (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
        #             1.0, (0, 0, 0), 2)

        # æ°´å¹³æ‹¼æ¥
        comparison = np.hstack([orig_small, overlay_small])

        # ä¿å­˜å¯¹æ¯”å›¾
        comparison_path = os.path.join(save_dir, f"{base_name}_before_after.jpg")
        cv2.imwrite(comparison_path, comparison)
        print(f"   ğŸ“Š å‰åå¯¹æ¯”: {comparison_path}")

        return comparison

    # ğŸ¯ å¦ä¸€ç§çº¯è½®å»“æ˜¾ç¤ºæ–¹æ³•
    def create_contour_only_overlay(self, image_path, detections, save_dir="./", image_name="result"):
        """åˆ›å»ºåªæ˜¾ç¤ºè½®å»“çš„å åŠ ï¼ˆä¿æŒåŸå›¾å®Œå…¨æ¸…æ™°ï¼‰"""

        original_image = cv2.imread(image_path)
        if original_image is None:
            return None

        h, w, _ = original_image.shape
        base_name = os.path.splitext(image_name)[0]

        # åˆ›å»ºä¿å­˜ç›®å½•
        contour_dir = os.path.join(save_dir, "contour_overlays")
        os.makedirs(contour_dir, exist_ok=True)

        print("ğŸ¨ åˆ›å»ºè½®å»“å åŠ å¯è§†åŒ–...")

        # å®Œå…¨ä¿æŒåŸå›¾ä¸å˜ï¼Œåªæ·»åŠ è½®å»“
        contour_overlay = original_image.copy()

        for det in detections:
            obj_type = det['type']
            phrase = det['phrase']
            confidence = det['confidence']
            sam_mask = det.get('sam_mask')
            box_xyxy = det['box_xyxy']

            # è·å–é¢œè‰²
            color = self.get_color_for_class(phrase, is_dynamic=(obj_type == 'dynamic'))
            # å¢å¼ºé¢œè‰²äº®åº¦
            color = [min(255, int(c * 1.8)) for c in color]

            # ç»˜åˆ¶è½®å»“
            if sam_mask is not None:
                contours, _ = cv2.findContours(sam_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                # ç²—è½®å»“
                cv2.drawContours(contour_overlay, contours, -1, color, 3)
                # ç»†å†…è½®å»“å¢å¼ºå¯¹æ¯”
                cv2.drawContours(contour_overlay, contours, -1, (255, 255, 255), 1)
            # else:
            #     # è¾¹ç•Œæ¡†è½®å»“
            #     # x1, y1, x2, y2 = box_xyxy.cpu().numpy().astype(int)
            #     # cv2.rectangle(contour_overlay, (x1, y1), (x2, y2), color, 3)
            #     # cv2.rectangle(contour_overlay, (x1 + 1, y1 + 1), (x2 - 1, y2 - 1), (255, 255, 255), 1)

            # ç®€æ´æ ‡ç­¾
            x1, y1, x2, y2 = box_xyxy.cpu().numpy().astype(int)
            label = f"{phrase}"

            # æ ‡ç­¾èƒŒæ™¯
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.5
            font_thickness = 1

            (text_width, text_height), _ = cv2.getTextSize(label, font, font_scale, font_thickness)

            # åŠé€æ˜æ ‡ç­¾èƒŒæ™¯
            # label_bg = contour_overlay.copy()
            # cv2.rectangle(label_bg, (x1, y1 - text_height - 6), (x1 + text_width + 6, y1), color, -1)
            # cv2.addWeighted(contour_overlay, 0.8, label_bg, 0.2, 0, contour_overlay)

            # ç™½è‰²æ–‡å­—
            # cv2.putText(contour_overlay, label, (x1 + 3, y1 - 3), font, font_scale, (255, 255, 255), font_thickness)

        # ä¿å­˜è½®å»“å åŠ 
        contour_path = os.path.join(contour_dir, f"{base_name}_contour_only.jpg")
        cv2.imwrite(contour_path, contour_overlay)

        print(f"âœ… è½®å»“å åŠ å®Œæˆ: {contour_path}")
        return contour_overlay

    def _detect_with_prompt_and_sam(self, image, prompt, object_type, w, h):
        """ä½¿ç”¨æŒ‡å®šæç¤ºè¯æ£€æµ‹ç‰©ä½“å¹¶åº”ç”¨SAMåˆ†å‰²"""
        detections = []

        try:
            # Grounding DINOæ£€æµ‹
            with torch.no_grad():
                boxes, logits, phrases = predict(
                    model=self.grounding_dino_model,
                    image=image,
                    caption=prompt,
                    box_threshold=self.box_threshold,
                    text_threshold=self.text_threshold,
                    device=self.device
                )

            print(f"   Grounding DINOæ£€æµ‹åˆ° {len(boxes)} ä¸ª{object_type}ç‰©ä½“")

            # å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
            for i, (box, logit, phrase) in enumerate(zip(boxes, logits, phrases)):
                confidence = logit.item()

                # ç½®ä¿¡åº¦è¿‡æ»¤
                if confidence < self.min_confidence:
                    continue

                # è½¬æ¢åæ ‡
                box_xyxy = box_ops.box_cxcywh_to_xyxy(box.unsqueeze(0)) * torch.tensor([w, h, w, h])
                x1, y1, x2, y2 = box_xyxy[0].cpu().numpy().astype(int)

                # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)

                # é‡æ–°åˆ†ç±»
                actual_type = self.classify_detection(phrase)
                if actual_type == "unknown":
                    actual_type = object_type

                detection = {
                    'box': box,
                    'box_xyxy': box_xyxy[0],
                    'confidence': confidence,
                    'phrase': phrase,
                    'type': actual_type,
                    'original_type': object_type,
                    'sam_mask': None,
                    'sam_success': False
                }

                # ğŸ¯ SAMåˆ†å‰²
                if self.sam_predictor:
                    try:
                        input_box = np.array([x1, y1, x2, y2])
                        masks, sam_scores, _ = self.sam_predictor.predict(
                            point_coords=None,
                            point_labels=None,
                            box=input_box[None, :],
                            multimask_output=False,
                        )

                        if len(masks) > 0 and masks[0] is not None:
                            sam_mask = masks[0].astype(np.uint8)
                            detection['sam_mask'] = sam_mask
                            detection['sam_success'] = True
                            detection['sam_score'] = sam_scores[0] if len(sam_scores) > 0 else 0.0
                            print(f"   âœ… SAMåˆ†å‰²æˆåŠŸ: {phrase} (mask pixels: {np.sum(sam_mask)})")
                        else:
                            print(f"   âŒ SAMåˆ†å‰²å¤±è´¥: {phrase}")

                    except Exception as e:
                        print(f"   âŒ SAMåˆ†å‰²å‡ºé”™: {phrase} - {e}")

                detections.append(detection)

            # æŒ‰ç½®ä¿¡åº¦æ’åº
            detections.sort(key=lambda x: x['confidence'], reverse=True)
            print(f"   è¿‡æ»¤åä¿ç•™ {len(detections)} ä¸ª{object_type}ç‰©ä½“")

        except Exception as e:
            print(f"âŒ {object_type}ç‰©ä½“æ£€æµ‹å¤±è´¥: {e}")

        return detections

    def _post_process_detections_with_sam(self, all_detections, w, h):
        """åå¤„ç†æ£€æµ‹ç»“æœï¼ŒåŒ…æ‹¬SAM maskçš„NMS"""
        if not all_detections:
            return []

        # å°ºå¯¸è¿‡æ»¤
        processed_detections = []
        for det in all_detections:
            x1, y1, x2, y2 = det['box_xyxy'].cpu().numpy()
            box_area = (x2 - x1) * (y2 - y1)
            image_area = h * w

            if box_area < 0.001 * image_area or box_area > 0.8 * image_area:
                continue

            processed_detections.append(det)

        if not processed_detections:
            return []

        # åˆ†åˆ«å¯¹åŠ¨æ€å’Œé™æ€ç‰©ä½“åº”ç”¨NMS
        dynamic_dets = [d for d in processed_detections if d['type'] == 'dynamic']
        static_dets = [d for d in processed_detections if d['type'] == 'static']

        final_detections = []

        # å¯¹åŠ¨æ€ç‰©ä½“åº”ç”¨NMS
        if dynamic_dets:
            dynamic_nms = self._apply_nms_with_sam(dynamic_dets, iou_threshold=0.5)
            final_detections.extend(dynamic_nms)

        # å¯¹é™æ€ç‰©ä½“åº”ç”¨NMS
        if static_dets:
            static_nms = self._apply_nms_with_sam(static_dets, iou_threshold=0.6)
            final_detections.extend(static_nms)

        return final_detections

    def _apply_nms_with_sam(self, detections, iou_threshold=0.5):
        """åº”ç”¨è€ƒè™‘SAM maskçš„NMS"""
        if len(detections) <= 1:
            return detections

        boxes = torch.stack([det['box_xyxy'] for det in detections])
        scores = torch.tensor([det['confidence'] for det in detections])

        keep_indices = torchvision.ops.nms(boxes, scores, iou_threshold)
        return [detections[i] for i in keep_indices.cpu().numpy()]

    def _create_comprehensive_visualization(self, image_source, detections, save_dir, image_name):
        """ğŸ¨ åˆ›å»ºå®Œæ•´çš„å¯è§†åŒ–"""
        base_name = os.path.splitext(image_name)[0]
        h, w = image_source.shape[:2]

        # 1. åˆ›å»ºåŸºç¡€å›¾åƒå‰¯æœ¬
        combined_image = image_source.copy()
        dynamic_only_image = image_source.copy()
        static_only_image = image_source.copy()
        sam_visualization = image_source.copy()

        dynamic_count = 0
        static_count = 0
        sam_success_count = 0

        # 2. å¤„ç†æ¯ä¸ªæ£€æµ‹ç»“æœ
        for det in detections:
            x1, y1, x2, y2 = det['box_xyxy'].cpu().numpy().astype(int)
            confidence = det['confidence']
            phrase = det['phrase']
            obj_type = det['type']
            sam_mask = det.get('sam_mask')
            sam_success = det.get('sam_success', False)

            # è·å–é¢œè‰²
            color = self.get_color_for_class(phrase, is_dynamic=(obj_type == 'dynamic'))

            if obj_type == 'dynamic':
                dynamic_count += 1
            else:
                static_count += 1

            if sam_success:
                sam_success_count += 1

            label = f"{phrase}: {confidence:.2f}"

            # 3. ç»˜åˆ¶è¾¹ç•Œæ¡†åœ¨å„ç§å›¾åƒä¸Š
            self._draw_detection_box(combined_image, (x1, y1, x2, y2), label, color, obj_type)

            if obj_type == 'dynamic':
                self._draw_detection_box(dynamic_only_image, (x1, y1, x2, y2), label, color, obj_type)
            else:
                self._draw_detection_box(static_only_image, (x1, y1, x2, y2), label, color, obj_type)

            # 4. ğŸ¯ å¤„ç†SAM maskå¯è§†åŒ–
            if sam_mask is not None and sam_success:
                mask_bool = sam_mask.astype(bool)

                # SAMå¯è§†åŒ– - åŠé€æ˜å åŠ 
                overlay_layer = np.zeros_like(sam_visualization)
                overlay_layer[mask_bool] = color
                sam_visualization = cv2.addWeighted(sam_visualization, 0.7, overlay_layer, 0.3, 0)

        # 5. æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        self._add_statistics_text(combined_image, dynamic_count, static_count, sam_success_count)
        self._add_statistics_text(dynamic_only_image, dynamic_count, 0, 0, "DYNAMIC OBJECTS ONLY")
        self._add_statistics_text(static_only_image, 0, static_count, 0, "STATIC OBJECTS ONLY")
        self._add_statistics_text(sam_visualization, dynamic_count, static_count, sam_success_count, "SAM SEGMENTATION")

        # 6. ä¿å­˜æ‰€æœ‰å¯è§†åŒ–ç»“æœ
        save_paths = {
            'combined': f"{base_name}_combined_detection.jpg",
            'dynamic_only': f"{base_name}_dynamic_only.jpg",
            'static_only': f"{base_name}_static_only.jpg",
            'sam_overlay': f"{base_name}_sam_overlay.jpg",
        }

        # ä¿å­˜å›¾åƒ
        cv2.imwrite(os.path.join(save_dir, save_paths['combined']), combined_image)
        cv2.imwrite(os.path.join(save_dir, save_paths['dynamic_only']), dynamic_only_image)
        cv2.imwrite(os.path.join(save_dir, save_paths['static_only']), static_only_image)
        cv2.imwrite(os.path.join(save_dir, save_paths['sam_overlay']), sam_visualization)

        # ä¿å­˜åŸå§‹SAM masks
        self._save_individual_sam_masks(detections, save_dir, base_name)

        print(f"âœ… å®Œæ•´å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ° {save_dir}")
        print(f"   ğŸ¨ ç»¼åˆæ£€æµ‹: {save_paths['combined']}")
        print(f"   ğŸ”´ åŠ¨æ€ç‰©ä½“: {save_paths['dynamic_only']}")
        print(f"   ğŸŸ¢ é™æ€ç‰©ä½“: {save_paths['static_only']}")
        print(f"   ğŸ¯ SAMå åŠ : {save_paths['sam_overlay']}")

    def _draw_detection_box(self, image, box, label, color, obj_type):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†"""
        x1, y1, x2, y2 = box

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        thickness = 3 if obj_type == 'dynamic' else 2
        cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)

        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        font_thickness = 2

        # æ·»åŠ ç±»å‹æ ‡è¯†
        type_prefix = "[D] " if obj_type == 'dynamic' else "[S] "
        full_label = type_prefix + label

        # è·å–æ–‡æœ¬å¤§å°
        (text_width, text_height), baseline = cv2.getTextSize(
            full_label, font, font_scale, font_thickness
        )

        # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
        # bg_color = tuple(int(c * 0.8) for c in color)
        # cv2.rectangle(
        #     image,
        #     (x1, y1 - text_height - 10),
        #     (x1 + text_width + 10, y1),
        #     bg_color,
        #     -1
        # )

        # ç»˜åˆ¶æ–‡æœ¬
        # cv2.putText(
        #     image,
        #     full_label,
        #     (x1 + 5, y1 - 5),
        #     font,
        #     font_scale,
        #     (255, 255, 255),
        #     font_thickness
        # )

    def _add_statistics_text(self, image, dynamic_count, static_count, sam_count=0, title="DETECTION RESULTS"):
        """åœ¨å›¾åƒä¸Šæ·»åŠ ç»Ÿè®¡ä¿¡æ¯"""
        h, w = image.shape[:2]

        # ç»Ÿè®¡æ–‡æœ¬
        stats_lines = [
            title,
            f"Dynamic Objects: {dynamic_count}",
            f"Static Objects: {static_count}",
            f"Total Objects: {dynamic_count + static_count}"
        ]

        if sam_count > 0:
            stats_lines.append(f"SAM Success: {sam_count}")

        # æ–‡æœ¬å‚æ•°
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        font_thickness = 2
        line_height = 30

        # è®¡ç®—æ–‡æœ¬åŒºåŸŸå¤§å°
        max_width = 0
        for line in stats_lines:
            (text_width, _), _ = cv2.getTextSize(line, font, font_scale, font_thickness)
            max_width = max(max_width, text_width)

        # ç»˜åˆ¶èƒŒæ™¯
        # bg_height = len(stats_lines) * line_height + 20
        # cv2.rectangle(image, (10, 10), (max_width + 30, bg_height), (0, 0, 0), -1)
        # cv2.rectangle(image, (10, 10), (max_width + 30, bg_height), (255, 255, 255), 2)

        # ç»˜åˆ¶æ–‡æœ¬
        # for i, line in enumerate(stats_lines):
        #     y = 35 + i * line_height
        #     color = (255, 255, 255) if i == 0 else (0, 255, 255)
        #     cv2.putText(image, line, (20, y), font, font_scale, color, font_thickness)

    def _save_individual_sam_masks(self, detections, save_dir, base_name):
        """ä¿å­˜å•ç‹¬çš„SAM masks"""
        masks_dir = os.path.join(save_dir, "masks")

        for i, det in enumerate(detections):
            if det.get('sam_mask') is not None:
                mask = det['sam_mask']
                phrase = det['phrase'].replace(' ', '_').replace('/', '_')
                obj_type = det['type']

                # ä¿å­˜äºŒå€¼mask
                mask_path = os.path.join(masks_dir, f"{base_name}_{obj_type}_{i:02d}_{phrase}_mask.png")
                cv2.imwrite(mask_path, mask * 255)

                # ä¿å­˜å½©è‰²mask
                color = self.get_color_for_class(det['phrase'], is_dynamic=(obj_type == 'dynamic'))
                colored_individual_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)
                colored_individual_mask[mask.astype(bool)] = color

                colored_path = os.path.join(masks_dir, f"{base_name}_{obj_type}_{i:02d}_{phrase}_colored.png")
                cv2.imwrite(colored_path, colored_individual_mask)


# ================================
# ä¸»å‡½æ•°å’Œæ‰¹é‡å¤„ç†ç¤ºä¾‹
# ================================

def main():
    """å•å¼ å›¾ç‰‡å¤„ç†ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨åŠ¨æ€é™æ€ç‰©ä½“æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 50)

    # é…ç½®è·¯å¾„
    grounding_dino_config = "/home/zwk/ä¸‹è½½/S3PO-GS-main/GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py"
    grounding_dino_checkpoint = "/home/zwk/ä¸‹è½½/S3PO-GS-main/groundingdino_swint_ogc.pth"
    sam_checkpoint = "/home/zwk/ä¸‹è½½/S3PO-GS-main/sam_vit_h_4b8939.pth"

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = EnhancedDynamicStaticDetector(
        grounding_dino_config=grounding_dino_config,
        grounding_dino_checkpoint=grounding_dino_checkpoint,
        sam_checkpoint=sam_checkpoint,
        device="cuda"
    )

    # æµ‹è¯•å›¾åƒ
    test_image = "/home/zwk/dataset/SemanticKITTI/SemanticKITTI/dataset/sequences/04/image_2/000004.png"

    if os.path.exists(test_image):
        print("\nğŸ¯ å¼€å§‹æ£€æµ‹...")
        detections = detector.detect_objects_with_sam(test_image, "./detection_results")

        print(f"\nğŸ“Š æ£€æµ‹ç»“æœ:")
        print(f"   æ€»æ£€æµ‹æ•°: {len(detections)}")
        print(f"   åŠ¨æ€ç‰©ä½“: {len([d for d in detections if d['type'] == 'dynamic'])}")
        print(f"   é™æ€ç‰©ä½“: {len([d for d in detections if d['type'] == 'static'])}")

    else:
        print(f"âš ï¸ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")

    print("\nâœ… æ£€æµ‹å®Œæˆ!")


def main_batch():
    """æ‰¹é‡å¤„ç†ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ‰¹é‡åŠ¨æ€é™æ€ç‰©ä½“æ£€æµ‹ç³»ç»Ÿ")
    print("=" * 50)

    # é…ç½®è·¯å¾„
    grounding_dino_config = "/home/zwk/ä¸‹è½½/S3PO-GS-main/GroundingDINO-main/groundingdino/config/GroundingDINO_SwinB_cfg.py"
    grounding_dino_checkpoint = "/home/zwk/ä¸‹è½½/groundingdino_swinb_cogcoor.pth"
    sam_checkpoint = "/home/zwk/ä¸‹è½½/S3PO-GS-main/sam_vit_h_4b8939.pth"

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = EnhancedDynamicStaticDetector(
        grounding_dino_config=grounding_dino_config,
        grounding_dino_checkpoint=grounding_dino_checkpoint,
        sam_checkpoint=sam_checkpoint,
        device="cuda"
    )

    # æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
    input_folder = "/home/zwk/dataset/SemanticKITTI/SemanticKITTI/dataset/sequences/08/image_2/"
    output_folder = "./batch_detection_results_ours"

    if os.path.exists(input_folder):
        print("\nğŸ¯ å¼€å§‹æ‰¹é‡æ£€æµ‹...")
        batch_results = detector.detect_folder_images(input_folder, output_folder)
        print("âœ… æ‰¹é‡æ£€æµ‹å®Œæˆ!")
    else:
        print(f"âš ï¸ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")


if __name__ == "__main__":
    # å¯ä»¥é€‰æ‹©å•å¼ å›¾ç‰‡å¤„ç†æˆ–æ‰¹é‡å¤„ç†
    print("ğŸ“‹ è¯·é€‰æ‹©å¤„ç†æ¨¡å¼:")
    print("1. å•å¼ å›¾ç‰‡å¤„ç†")
    print("2. æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹")

    try:
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()
        if choice == "2":
            main_batch()
        elif choice == "1":
            main()
        else:
            print("âš ï¸ æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤è¿è¡Œå•å¼ å›¾ç‰‡å¤„ç†")
            main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")